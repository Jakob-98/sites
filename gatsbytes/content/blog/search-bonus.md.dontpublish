---
title: "Encoding hidden prompt in LLMs as potential attack vector."
date: "2024-01-15"
path: "/gpt-hidden-prompt-base64-attack-vector"
image: "https://jakobs.dev/media/jakobsdev.png"
description: "Inject hidden prompt in LLMs using Base64 encoding."
tags: ["LLM", "tech", "gpt-4"]
---

# Showcase: Azure AI Hybrid Search unexpected results gotcha

This document describes a gotcha in Azure AI Search hybrid queries where unexpected results are returned.

The context is of these findings are an ISE engagement with a customer indexing millions of documents in Azure AI Search. During this, I set out to answer questions on filering and matching syntax as well as pre/post-filter performance for hybrid search. Views and opinions are my own.

## Key takeaway

Traditional full-text search return matches if and only if there is a match. Vector search always returns `k` number of matches, which can be nonsensical (see [here](https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-query?tabs=query-2023-11-01%2Cfilter-2023-11-01#quantity-of-ranked-results-in-a-vector-query-response)). Given the way hybrid search reranks the sum of results from full-text and vector search, hybrid search can return results which would not be expected given (regex) matching constraints in the `search_text` argument.

If you are simply filtering on a field, use `filter` [(filter syntax refs)](https://learn.microsoft.com/en-us/azure/search/search-query-odata-filter). This is a 'hard' filter, meaning that results which do not match are not included in the end-results for (hybrid) search.

## Brief reiteration on search methods

Azure AI Search offers these three search methods:

1. Keyword search: fulltext and semantic
    1. Fulltext: `queryType` sets the parser: simple, or full. The default simple query parser is optimal for full text search. Full enables Lucene query parser: for advanced query constructs like regular expressions, proximity search, fuzzy and wildcard search. [Full-text query how-to - Azure AI Search | Microsoft Learn](https://learn.microsoft.com/en-us/azure/search/search-query-create?tabs=portal-text-query)
    1. Semantic: Semantic ranker is a collection of query-related capabilities that improve the quality of an initial BM25-ranked or RRF-ranked search result for text-based queries. When you enable it on your search service, semantic ranking extends the query execution pipeline in two ways:
        1. Secondary ranking score & captions and answers in the response.  [Semantic ranking - Azure AI Search | Microsoft Learn](https://learn.microsoft.com/en-us/azure/search/semantic-search-overview)
1. Vector search: [docs](https://learn.microsoft.com/en-us/azure/search/vector-search-overview) - uses embeddings and distance in latent space to retrieve semantically relevant documents.
1. Hybrid search: combines both results, and reranks, e.g. using RRF [(docs)](https://learn.microsoft.com/en-us/azure/search/hybrid-search-how-to-query)

## Technique - filtering and matching documents in Azure AI Search

For matching and filtering documents, these two approaches were most useful for our use-cases:

1. Using OData language and `filter` argument: [OData language overview - Azure AI Search | Microsoft Learn](https://learn.microsoft.com/en-us/azure/search/query-odata-filter-orderby-syntax)
1. Using the `search_text` argument and `query_type="full"` so we are able to use the Lucene queryparser syntax: we can match results e.g., using regular expressions [Lucene query syntax - Azure AI Search | Microsoft Learn](https://learn.microsoft.com/en-us/azure/search/query-lucene-syntax).

## Gotcha example - Where things turn sour

Imagine the following query. We are interesed in filtering on a specific id (the full set only contains one document with this ID), but we also match the id to contain `1234` using a regex lucene query. Obviously, this matches and we get a result:

```python
limit = 10
select = 'id,content'
search_text = "id:/.*1234.*/"
search_client = sc
result = await search_client.search(
        search_text=search_text,
        top=limit,
        select=select,
        query_type="full",  # Set query type to full to enable lucene/regex queries
        filter = "id eq 'A001-AB-1234_chunk_0'"
    )
async for doc in result:
    print(doc)

# >
# {'id': 'A001-AB-1234_chunk_0', 'content':....
#
```

Now, we change the regex query to (not) match `4321` in the id, and we obviously get no result:

```python
limit = 10
select = 'id,content'
search_text = "id:/.*4321.*/"
search_client = sc
result = await search_client.search(
        search_text=search_text,
        top=limit,
        select=select,
        query_type="full",  # Set query type to full to enable lucene/regex queries
        filter = "id eq 'A001-AB-1234_chunk_0'"
    )
async for doc in result:
    print(doc)

# >
# NO RESULTS
#
```

What happens if we add hybrid search to the mix, but still include the unmatching `4321` in the id?

``` python
# Hybrid search with regex-like query, yielding unexpected (1234) result (hybrid).
# (using helper function to set up the embedding, ...)
async for doc in await vector_search_with_lucene(
    limit=10,
    query_to_embed="failing gear unit", # some query which closely resembles the text in the content
    search_text = "id:/.*4321.*/",
    query_type= "full",
    select='id,content',
    search_client=sc,
    vector_filter_mode="preFilter",
    filter = "id eq 'A001-AB-1234_chunk_0'"
):
    print(doc)

# >
# {'id': 'A001-AB-1234_chunk_0', 'content':....
#
```

Notice how in this case, we *do* get the result back, but the id doesn't match the regex query.

**Reasoning**:

Azure AI Hybrid search reranks documents after both the vector search and fulltext search are finished. The `search_text` argument allows for strict (regex) matching, but this matching only applies to the fulltext search. Since we pre-filter on a specific document, vector search will always yield this result (note: this holds even if the neighbour of the embedded query isn't too similar, since we always try to return 10 results - which then must include our single document). After both the vector and text search are executed, the hybrid results includes results which would not be expected from just full-text search.

---

## Bonus: performance of pre-filtering and post-filtering on our index

When using filtering in the context of vector/hybrid search, the set of results and performance is influenced by filting before or after the executing the query. Here, we explore both options on a medium-sized index.

### Filtering and vector queries

[Official docs on vector search filters.](https://learn.microsoft.com/en-us/azure/search/vector-search-filters).

The main points made in the docs on filters in vector queries which are relevant to us are:

1. Prefiltering: applies filters before query execution, reducing the search surface but can be slower, especially on larger datasets.
1. Postfiltering: applies filters after query execution, which can be faster but may return fewer results than the specified number if the filters are highly selective (i.e., it may miss documents existing in the index).
1. The default mode is prefiltering, which is recommended for *ensuring a complete set of results* but is orders of magnitude slower.

We will run a small set of experiments on our own index to confirm these findings. We want to make sure that:

1. Prefiltering and postfiltering behaviors align with the benchmark, since our index size (~6 million documents) falls between the medium and large.
1. The performance impact of each filtering mode is understood.
1. Filter syntax is understood.

#### Filter and vector query experiment

We will be using the 'REDACTED' index with 5,955,092 items, storage: 162.2 GB, vector index size: 34.38 GB.

According to the docs on vector search with filters, filtering for a small set of documents is the least performant. We will therefore filter for a specific assetID, which should yield a <1% of the total index size.

#### Method

1. Retrieve 5000 document IDs
1. Shuffle the document IDs. 250 randomly sampled IDs will be used for preFilter, 250 randomy sampled IDs will be used for postFilter.
1. Generate 500 random (faker.sentence "lorem") sentences, embed them.
1. Perform hybrid search.

reference code snippet:

```python
timings = []
num_results = []
from tqdm import tqdm

for _id, query in tqdm(zip(id_list[:250], query_list[:250])):
    query_to_embed = query
    limit = 50
    vector_query = VectorizedQuery(vector= await get_embedding(query_to_embed), k_nearest_neighbors=limit, fields="embedding")
    select = 'id,content,sourcepage'
    search_text = "some_text"
    search_client = sc

    start_time = time.time()
    result = search_client.search(
            search_text=search_text,
            top=limit,
            select=select,
            query_type="full",  # Set query type to full to enable regex
            filter = f"id eq '{_id}'",
            vector_queries=[vector_query],
            vector_filter_mode="preFilter",
        )
    r_lst = []
    for page in result.by_page():
        for result in page:
            r_lst.append(result)
    timings += [time.time()-start_time]
    num_results += [len(r_lst)]
```

#### Results

| Type       | #n queries | total time | found results          |
|------------|------------|------------|------------------------|
| preFilter  | 250        | 44.07s     | 12500 (limit 50 * 250) |
| postFilter | 250        | 18.63s     | 160                    |

As we can see, the postFilter is quicker by a factor greater than 2, but lots of results are missed.

Times plotted:

![prefilter](./media/prefilter_query_times.png)
![postfilter](./media/postfilter_query_times.png)
